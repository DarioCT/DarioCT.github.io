<!DOCTYPE html>
<html>
<head>
	<meta charset="utf-8">
    <meta name="viewport" content="width=device-width">
    <meta name="viewport" content="initial-scale=1">

	<title>Dario Culig-Tokic / Reinforcement Learning</title>

    <link rel="icon" href="favicon.png" type="image/png">
	<link href="styleProject.css" rel="stylesheet" type="text/css">
    <link href='https://fonts.googleapis.com/css?family=Poiret+One&subset=latin,latin-ext' rel='stylesheet' type='text/css'>
</head>
<body>
    <div id="wraper">
        <div id="menu">
            <a href="index.html" style="text-decoration: none;"><h1>Dario Culig-Tokic</h1></a>
            <div id="projectList">
                <div id="menuOne">
                    <a id="projects" href="Regression Problem.html">
                        <p id="projects">Regression Problem</p>
                    </a>
                    <a id="projects" href="Classification Problem.html">
                        <p id="projects">Classification Problem</p>
                    </a>
                    <a id="projects" href="Time-Series Problem.html">
                        <p id="projects">Time-Series Problem</p>
                    </a>
                </div>
                <div id="menuTwo">
                    <a id="projects" href="Unsupervised Learning.html">
                        <p id="projects">Unsupervised Learning</p>
                    </a>
                    <a id="projects" href="Supervised Learning.html">
                        <p id="projects">Supervised Learning</p>
                    </a>
                    <a id="projects" href="Reinforcement Learning.html">
                        <p id="projects">Reinforcement Learning</p>
                    </a>
                </div>
                 <div id="menuTwo">
                    <a id="projects" href="Deep Neural Networks.html">
                        <p id="projects">Deep Neural Networks</p>
                    </a>
                    <a id="projects" href="Decision Tree Models.html">
                        <p id="projects">Decision Tree Models</p>
                    </a>
                    <!--<a id="projects" href="Naive Bayes Models.html">
                        <p id="projects">Naive Bayes Models</p>
                    </a>-->
                    <a id="projects" href="Dimensionality Reduction.html">
                        <p id="projects">Dimensionality Reduction</p>
                    </a>
                    <a id="projects" href="SVM.html">
                        <p id="projects">SVM, KNN, ElasticNet, Lasso, Ridge</p>
                    </a>
                </div>
            </div>
            <div id="social">
                <a href="https://hr.linkedin.com/in/darioculigtokic" target="_blank"><img src="linkedin.png" width="42" height="42" title="Linkedin" alt="IN"></a>
                <a id="mail" href="mailto:dculigtokic@gmail.com"><img src="email.png" width="42" height="42" title="e-mail" alt="@"></a>
		<!--<a id="mail" href="CV.pdf" target="_blank"><img src="CV.png" width="42" height="42" title="Resume" alt="CV"></a>-->
            </div>
        </div>
        <div id="page">
            <h2>Reinforcement Learning</h2>
            <p id="text2">
                Reinforcement learning is an area of machine learning concerned with how software agents ought to take actions in an environment so as to maximize some notion of cumulative reward. In machine learning, the environment is typically formulated as a Markov Decision Process (MDP), as many reinforcement learning algorithms for this context utilize dynamic programming techniques. The main difference between the classical dynamic programming methods and reinforcement learning algorithms is that the latter do not assume knowledge of an exact mathematical model of the MDP and they target large MDPs where exact methods become infeasible.
            </p>
            <p id="textKeyWords">
                 Reinforcement learning differs from standard supervised learning in that correct input/output pairs need not be presented, and sub-optimal actions need not be explicitly corrected. Instead the focus is on performance, which involves finding a balance between exploration and exploitation.
	        </p>
        <div id="projectList2">
                <p id="projects2">&#9655 Teach a Quadcopter How to Fly</p>
                 <p id="text2">
                In this project, a DDPG agent was trained to can fly a quadcopter. Building off the prior work of on Deterministic Policy Gradients, a policy-gradient actor-critic algorithm called DDPG - Deep Deterministic Policy Gradients was produced. It is an off-policy and model-free, and it uses some of the deep learning tricks that were introduced along with Deep Q-Networks (hence the “deep” of DDPG).
                </p>
                <p id="textKeyWords">
                Key words: Deep Reinforcement Learning, Deep Deterministic Policy Gradients, Actor Critic Agents, Algorithm Optimisation, Quadcopter
                </p>
                <p id="textKeyWords">
                Created using: Python (Keras, SciKit Learn, NumPy, Pandas, Seaborn)
                </p>
                <p id="textKeyWords">
                <a id="projectLink" href="Titanic Survival Exploration/Titanic Survival Exploration.html" target="_blank">Take a look at the project</a>
                </p>
            </div>
        </div>
    </div>
</body>
</html>
